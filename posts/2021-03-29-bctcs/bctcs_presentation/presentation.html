<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
"http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1" />
<title>Trustable Machine Learning Systems</title>
<meta name="generator" content="Org mode" />
<meta name="author" content="Jay Morgan" />
<style type="text/css">
 <!--/*--><![CDATA[/*><!--*/
  .title  { text-align: center;
             margin-bottom: .2em; }
  .subtitle { text-align: center;
              font-size: medium;
              font-weight: bold;
              margin-top:0; }
  .todo   { font-family: monospace; color: red; }
  .done   { font-family: monospace; color: green; }
  .priority { font-family: monospace; color: orange; }
  .tag    { background-color: #eee; font-family: monospace;
            padding: 2px; font-size: 80%; font-weight: normal; }
  .timestamp { color: #bebebe; }
  .timestamp-kwd { color: #5f9ea0; }
  .org-right  { margin-left: auto; margin-right: 0px;  text-align: right; }
  .org-left   { margin-left: 0px;  margin-right: auto; text-align: left; }
  .org-center { margin-left: auto; margin-right: auto; text-align: center; }
  .underline { text-decoration: underline; }
  #postamble p, #preamble p { font-size: 90%; margin: .2em; }
  p.verse { margin-left: 3%; }
  pre {
    border: 1px solid #ccc;
    box-shadow: 3px 3px 3px #eee;
    padding: 8pt;
    font-family: monospace;
    overflow: auto;
    margin: 1.2em;
  }
  pre.src {
    position: relative;
    overflow: auto;
    padding-top: 1.2em;
  }
  pre.src:before {
    display: none;
    position: absolute;
    background-color: white;
    top: -10px;
    right: 10px;
    padding: 3px;
    border: 1px solid black;
  }
  pre.src:hover:before { display: inline; margin-top: 14px;}
  /* Languages per Org manual */
  pre.src-asymptote:before { content: 'Asymptote'; }
  pre.src-awk:before { content: 'Awk'; }
  pre.src-C:before { content: 'C'; }
  /* pre.src-C++ doesn't work in CSS */
  pre.src-clojure:before { content: 'Clojure'; }
  pre.src-css:before { content: 'CSS'; }
  pre.src-D:before { content: 'D'; }
  pre.src-ditaa:before { content: 'ditaa'; }
  pre.src-dot:before { content: 'Graphviz'; }
  pre.src-calc:before { content: 'Emacs Calc'; }
  pre.src-emacs-lisp:before { content: 'Emacs Lisp'; }
  pre.src-fortran:before { content: 'Fortran'; }
  pre.src-gnuplot:before { content: 'gnuplot'; }
  pre.src-haskell:before { content: 'Haskell'; }
  pre.src-hledger:before { content: 'hledger'; }
  pre.src-java:before { content: 'Java'; }
  pre.src-js:before { content: 'Javascript'; }
  pre.src-latex:before { content: 'LaTeX'; }
  pre.src-ledger:before { content: 'Ledger'; }
  pre.src-lisp:before { content: 'Lisp'; }
  pre.src-lilypond:before { content: 'Lilypond'; }
  pre.src-lua:before { content: 'Lua'; }
  pre.src-matlab:before { content: 'MATLAB'; }
  pre.src-mscgen:before { content: 'Mscgen'; }
  pre.src-ocaml:before { content: 'Objective Caml'; }
  pre.src-octave:before { content: 'Octave'; }
  pre.src-org:before { content: 'Org mode'; }
  pre.src-oz:before { content: 'OZ'; }
  pre.src-plantuml:before { content: 'Plantuml'; }
  pre.src-processing:before { content: 'Processing.js'; }
  pre.src-python:before { content: 'Python'; }
  pre.src-R:before { content: 'R'; }
  pre.src-ruby:before { content: 'Ruby'; }
  pre.src-sass:before { content: 'Sass'; }
  pre.src-scheme:before { content: 'Scheme'; }
  pre.src-screen:before { content: 'Gnu Screen'; }
  pre.src-sed:before { content: 'Sed'; }
  pre.src-sh:before { content: 'shell'; }
  pre.src-sql:before { content: 'SQL'; }
  pre.src-sqlite:before { content: 'SQLite'; }
  /* additional languages in org.el's org-babel-load-languages alist */
  pre.src-forth:before { content: 'Forth'; }
  pre.src-io:before { content: 'IO'; }
  pre.src-J:before { content: 'J'; }
  pre.src-makefile:before { content: 'Makefile'; }
  pre.src-maxima:before { content: 'Maxima'; }
  pre.src-perl:before { content: 'Perl'; }
  pre.src-picolisp:before { content: 'Pico Lisp'; }
  pre.src-scala:before { content: 'Scala'; }
  pre.src-shell:before { content: 'Shell Script'; }
  pre.src-ebnf2ps:before { content: 'ebfn2ps'; }
  /* additional language identifiers per "defun org-babel-execute"
       in ob-*.el */
  pre.src-cpp:before  { content: 'C++'; }
  pre.src-abc:before  { content: 'ABC'; }
  pre.src-coq:before  { content: 'Coq'; }
  pre.src-groovy:before  { content: 'Groovy'; }
  /* additional language identifiers from org-babel-shell-names in
     ob-shell.el: ob-shell is the only babel language using a lambda to put
     the execution function name together. */
  pre.src-bash:before  { content: 'bash'; }
  pre.src-csh:before  { content: 'csh'; }
  pre.src-ash:before  { content: 'ash'; }
  pre.src-dash:before  { content: 'dash'; }
  pre.src-ksh:before  { content: 'ksh'; }
  pre.src-mksh:before  { content: 'mksh'; }
  pre.src-posh:before  { content: 'posh'; }
  /* Additional Emacs modes also supported by the LaTeX listings package */
  pre.src-ada:before { content: 'Ada'; }
  pre.src-asm:before { content: 'Assembler'; }
  pre.src-caml:before { content: 'Caml'; }
  pre.src-delphi:before { content: 'Delphi'; }
  pre.src-html:before { content: 'HTML'; }
  pre.src-idl:before { content: 'IDL'; }
  pre.src-mercury:before { content: 'Mercury'; }
  pre.src-metapost:before { content: 'MetaPost'; }
  pre.src-modula-2:before { content: 'Modula-2'; }
  pre.src-pascal:before { content: 'Pascal'; }
  pre.src-ps:before { content: 'PostScript'; }
  pre.src-prolog:before { content: 'Prolog'; }
  pre.src-simula:before { content: 'Simula'; }
  pre.src-tcl:before { content: 'tcl'; }
  pre.src-tex:before { content: 'TeX'; }
  pre.src-plain-tex:before { content: 'Plain TeX'; }
  pre.src-verilog:before { content: 'Verilog'; }
  pre.src-vhdl:before { content: 'VHDL'; }
  pre.src-xml:before { content: 'XML'; }
  pre.src-nxml:before { content: 'XML'; }
  /* add a generic configuration mode; LaTeX export needs an additional
     (add-to-list 'org-latex-listings-langs '(conf " ")) in .emacs */
  pre.src-conf:before { content: 'Configuration File'; }

  table { border-collapse:collapse; }
  caption.t-above { caption-side: top; }
  caption.t-bottom { caption-side: bottom; }
  td, th { vertical-align:top;  }
  th.org-right  { text-align: center;  }
  th.org-left   { text-align: center;   }
  th.org-center { text-align: center; }
  td.org-right  { text-align: right;  }
  td.org-left   { text-align: left;   }
  td.org-center { text-align: center; }
  dt { font-weight: bold; }
  .footpara { display: inline; }
  .footdef  { margin-bottom: 1em; }
  .figure { padding: 1em; }
  .figure p { text-align: center; }
  .equation-container {
    display: table;
    text-align: center;
    width: 100%;
  }
  .equation {
    vertical-align: middle;
  }
  .equation-label {
    display: table-cell;
    text-align: right;
    vertical-align: middle;
  }
  .inlinetask {
    padding: 10px;
    border: 2px solid gray;
    margin: 10px;
    background: #ffffcc;
  }
  #org-div-home-and-up
   { text-align: right; font-size: 70%; white-space: nowrap; }
  textarea { overflow-x: auto; }
  .linenr { font-size: smaller }
  .code-highlighted { background-color: #ffff00; }
  .org-info-js_info-navigation { border-style: none; }
  #org-info-js_console-label
    { font-size: 10px; font-weight: bold; white-space: nowrap; }
  .org-info-js_search-highlight
    { background-color: #ffff00; color: #000000; font-weight: bold; }
  .org-svg { width: 90%; }
  /*]]>*/-->
</style>
<script type="text/javascript">
// @license magnet:?xt=urn:btih:e95b018ef3580986a04669f1b5879592219e2a7a&dn=public-domain.txt Public Domain
<!--/*--><![CDATA[/*><!--*/
     function CodeHighlightOn(elem, id)
     {
       var target = document.getElementById(id);
       if(null != target) {
         elem.classList.add("code-highlighted");
         target.classList.add("code-highlighted");
       }
     }
     function CodeHighlightOff(elem, id)
     {
       var target = document.getElementById(id);
       if(null != target) {
         elem.classList.remove("code-highlighted");
         target.classList.remove("code-highlighted");
       }
     }
    /*]]>*///-->
// @license-end
</script>
<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        displayAlign: "center",
        displayIndent: "0em",

        "HTML-CSS": { scale: 100,
                        linebreaks: { automatic: "false" },
                        webFont: "TeX"
                       },
        SVG: {scale: 100,
              linebreaks: { automatic: "false" },
              font: "TeX"},
        NativeMML: {scale: 100},
        TeX: { equationNumbers: {autoNumber: "AMS"},
               MultLineWidth: "85%",
               TagSide: "right",
               TagIndent: ".8em"
             }
});
</script>
<script type="text/javascript"
        src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-AMS_HTML"></script>
</head>
<body>
<div id="preamble" class="status">
<h1 class="title">Trustable Machine Learning Systems</h1>
          <p class="subtitle">30th March 2021</p>
</div>
<div id="content">
<h1 class="title">Trustable Machine Learning Systems</h1>
<div class="NOTES" id="orgd02c714">
<p>
Hello, and thank you for joining me today. My name is Jay Morgan, I'm a doctoral
candidate at swansea university, and today I will be talking about one research
method to create trustable machine learning systems.
</p>

</div>

<div id="outline-container-org35d9274" class="outline-2">
<h2 id="org35d9274"><span class="section-number-2">1</span> - The Good, the bad, and the ugly</h2>
<div class="outline-text-2" id="text-1">

<div id="org8bb36d9" class="figure">
<p><img src="./images/thegoodbadugly-ml.png" alt="thegoodbadugly-ml.png" />
</p>
</div>

<div class="NOTES" id="org7cc8480">
<p>
Or perhaps as I will put it today: the good, bad and ugly of Machine Learning
</p>

</div>
</div>
</div>

<div id="outline-container-orgd0b0388" class="outline-2">
<h2 id="orgd0b0388"><span class="section-number-2">2</span> - Machine Learning at its "Good"</h2>
<div class="outline-text-2" id="text-2">

<div id="orgb3afd5c" class="figure">
<p><img src="./images/self-driving-car.gif" alt="self-driving-car.gif" />
</p>
</div>

<div class="NOTES" id="org4ad4ebf">
<p>
Let us begin with the good.
</p>

<p>
Machine Learning, and specifically Deep Learning, has achieved a level of speed of
computation, a level of accuracy, and perceived intelligence, that its actually
becoming very useful in our daily lives.
</p>

<p>
Over the last few years we're seeing a transformation the automotive industry, where
a big few car manufacturers are rushing to bring us unprecidented levels of
autonomous driving.
</p>

</div>
</div>
</div>

<div id="outline-container-orgdf2bd9f" class="outline-2">
<h2 id="orgdf2bd9f"><span class="section-number-2">3</span> - Machine Learning at its "Ugly"</h2>
<div class="outline-text-2" id="text-3">

<div id="org5903370" class="figure">
<p><img src="./images/fgsm_panda_image.png" alt="fgsm_panda_image.png" />
</p>
<p><span class="figure-number">Figure 3: </span><a href="https://pytorch.org/tutorials/beginner/fgsm_tutorial.html">https://pytorch.org/tutorials/beginner/fgsm_tutorial.html</a></p>
</div>

<div class="NOTES" id="org9e6337a">
<p>
But theres a twist. And the twist is this: Machine Learning and the 'intelligent'
models they create are not intelligent, and are subject to some various forms of attacks.
</p>

<p>
These attacks occur when specially crafted modifications are made to the input of the
image. When these modifications are applied, the ML model will usually output a
miss-classification with high confidence.
</p>

<p>
These types of attacks, adversarial attacks, have been shown to be very
effective at reducing even the-state-of-art classifier models to almost 0 zero accuracy.
</p>

</div>
</div>
</div>

<div id="outline-container-org508310a" class="outline-2">
<h2 id="org508310a"><span class="section-number-2">4</span> - Machine Learning at its "Bad"</h2>
<div class="outline-text-2" id="text-4">

<div id="org2c68c81" class="figure">
<p><img src="./images/signs.png" alt="signs.png" />
</p>
<p><span class="figure-number">Figure 4: </span>Huang, X., Kwiatkowska, M., Wang, S., &amp; Wu, M. (2017, July). Safety verification of deep neural networks. In International conference on computer aided verification (pp. 3-29). Springer, Cham.</p>
</div>

<div class="NOTES" id="org2f79ec4">
<p>
This presents a very serious problem for the use of ML in systems, like fully
autonomous vehicles, where safety is paramount.
</p>

<p>
If such a modification is made to the input used by these ML models, even as a result
of sensor defects, the result could cost human lives.
</p>

</div>
</div>
</div>

<div id="outline-container-orgfaa95f4" class="outline-2">
<h2 id="orgfaa95f4"><span class="section-number-2">5</span> - A life with formal methods</h2>
<div class="outline-text-2" id="text-5">

<div id="orgc252135" class="figure">
<p><img src="./images/thegoodgoodgood-ml.png" alt="thegoodgoodgood-ml.png" />
</p>
</div>

<div class="NOTES" id="org580811d">
<p>
I hope that our future aspirations that, not just of our project, but with Machine
Learning in general, that formal methods can become the norm and uncover the
uglyniness and so that we can transform it into all positives, all goods.
</p>

</div>
</div>
</div>

<div id="outline-container-org341ca01" class="outline-2">
<h2 id="org341ca01"><span class="section-number-2">6</span> - What's in todays talk</h2>
<div class="outline-text-2" id="text-6">
<ol class="org-ol">
<li>Explanation of Adversarial examples</li>
<li>Defining the upper-bounds on where to search for these examples</li>
<li>Creating Neural Networks and searching for adversarial examples using
satisfiability theories. How this can be implemented to enable verification of
Neural Network properties.</li>
</ol>

<div class="NOTES" id="orgf4f14a1">
<p>
So in today's talk, I will give a description of what adversarial examples are, then
a method for defining a search space in which to find them. Finally, I will introduce
you to an open-source project to verify the existence of adversarial examples using
satisfiability testing.
</p>

</div>
</div>
</div>

<div id="outline-container-orgaac3155" class="outline-2">
<h2 id="orgaac3155"><span class="section-number-2">7</span> - Adversarial examples (mathematical formalisation)</h2>
<div class="outline-text-2" id="text-7">

<div id="org1657055" class="figure">
<p><img src="./images/perturbation.png" alt="perturbation.png" height="200px" />
</p>
</div>

<p>
Given some classifier model \(\mathcal{F}: \mathbb{R}^{n \times m} \rightarrow Y, \ Y
\in \{0, 1, ..., k-1\}\) and some input \(\textbf{x}\), and adversarial is created by
the modification \(\epsilon\) within the range of \(r\) (i.e. \(\epsilon \leq r\)) that
will result in a miss-classification: \(\mathcal{F}(\textbf{x}) \neq
\mathcal{F}(\textbf{x} + \epsilon)\).
</p>

<div class="NOTES" id="orgd03966f">
<p>
Here we have a more formal definition of what an adversarial is. If we have some
classifier F. This classifier takes a vector, or in this case, a matrix input
representation of a image \(x\). The output of this function is a single class label
from \(k\) classes.
</p>

<p>
An adversarial example will then be some modification &epsilon; to this x where the
result will be a different output from the classifier. Typically, this &epsilon; value
will be bounded by some norm value. In this example we have an \(r\). I.e. this maximum
amount of change to pixels will be bounded by this \(r\).
</p>

<p>
In other words, to create an adversarial, it is necessary to find some, suitably
small, modification to the original input image, i.e. change of pixels, that will
result in the model outputing an incorrect class.
</p>

<p>
Often, we find that the modifications are not noticable to the human observer, but
yet, the model has a high degree of confidence in its incorrect prediction.
</p>

</div>
</div>
</div>

<div id="outline-container-org49a6183" class="outline-2">
<h2 id="org49a6183"><span class="section-number-2">8</span> - How do we choose an \(r\)</h2>
<div class="outline-text-2" id="text-8">

<div id="org93d4ffd" class="figure">
<p><img src="./images/eos.png" alt="eos.png" />
</p>
</div>

<div class="NOTES" id="org596110d">
<p>
And by modifying the amount of perturbation one can apply to the input, we have more
destructive modifications. But as you can see in these examples, each image still
looks like their respective number, despite any perturbation is applied.
</p>

<p>
Two things to note:
</p>
<ul class="org-ul">
<li>the less perturbed cases are included in the bigger r scenario</li>
<li>the potential amount of adversarials probably increases with r</li>
</ul>

</div>
</div>
</div>

<div id="outline-container-org40806d9" class="outline-2">
<h2 id="org40806d9"><span class="section-number-2">9</span> - Less clear with non-image data</h2>
<div class="outline-text-2" id="text-9">
<p>
Iris dataset - classifier aim: predict type of flower from 4 dimensional vector of
Sepal Length, Sepal Width, Petal Length, and Petal Width.
I.e. \(\mathcal{F}: \mathbb{R}^4 \rightarrow Y, \ Y \in \{0, 1, 2\}\).
</p>


<div id="org5d12e6d" class="figure">
<p><img src="./images/iris.png" alt="iris.png" height="400px" />
</p>
</div>

<div class="NOTES" id="org10bf566">
<p>
However, for non-image data, we must ask how much modification can we apply in order
to search for adversarial examples?
</p>

<p>
In this toy example we have the Iris dataset. Called so because we have 3 different
types of plant species indicated by the different coloured points. In this plot we
have plotted the Sepal Width against the Sepal Length. A Neural Network will take
these features such as Sepal Length or Width, and output a classification such as
Setosa.
</p>

<p>
For these two out of four total features, the Setosa class may be almost linearly
separated, the Versicolor and virginica classes are interdispersed using these two
Sepal features.
</p>

</div>
</div>
</div>

<div id="outline-container-org9b5bd91" class="outline-2">
<h2 id="org9b5bd91"><span class="section-number-2">10</span> - Applying a 'small' \(r\) can lead to overlaps of true class boundaries</h2>
<div class="outline-text-2" id="text-10">

<div id="org47856cd" class="figure">
<p><img src="./images/iris-boundaries.png" alt="iris-boundaries.png" />
</p>
</div>

<div class="NOTES" id="org124c4f7">
<p>
In this plot we have added a red outline to each point in the training data. This red
outline represents the maximum amount of perturbation, our \(r\) bound we talked about
before.
</p>

<p>
Even in this case where \(r\) is roughly 0.1, many modifications of the each point
would push across potential class boundaries. This may be certainly true for the
versicolor and viriginica classes. Yet for the Setosa class, we can be more sure that
we have not passed any class boundaries.
</p>

<p>
So we may once again ask the question: which $r$-bound should we use when search for
adversarial examples.
</p>

</div>
</div>
</div>

<div id="outline-container-org80c83b4" class="outline-2">
<h2 id="org80c83b4"><span class="section-number-2">11</span> - Generate a individual \(r\) for each data point</h2>
<div class="outline-text-2" id="text-11">

<div id="org45b7a74" class="figure">
<p><img src="./images/boundary.png" alt="boundary.png" />
</p>
<p><span class="figure-number">Figure 10: </span>geometric complexity of class boundaries</p>
</div>


<div id="orgb259fd6" class="figure">
<p><img src="./images/deceptive.png" alt="deceptive.png" />
</p>
<p><span class="figure-number">Figure 11: </span>sparsity/density of sampling from data manifold that consistutes the training data.</p>
</div>

<div class="NOTES" id="org22fa360">
<p>
Some of my research aims to answer this question, using the information presented in
the available data. Given a set of data, a individual $r$-bound will be computed for each
data point that will take into consideration the estimated class bounds, and how much
information there is present in the data.
</p>

<p>
We consider two properties of the data in the process of generating these
neighbourhoods. These are:
</p>

<p>
situations where differently labelled data points lay close together in
the topological space, and therefore any perturbation of the data points could result
in passing the class boundaries, while wrongly labelling the perturbation the same as
the original. We have just seen this with the previous plots of the Iris data.
</p>

<p>
Our second property is shown in figure 2. It concerns the number of samples from
different regions of the data manifold. In sparse regions (small numbers of samples),
estimated class boundaries mayseem deceivingly simple, e.g. linear with a wide
margin.
</p>

</div>
</div>
</div>

<div id="outline-container-orgfe6bbc3" class="outline-2">
<h2 id="orgfe6bbc3"><span class="section-number-2">12</span> - Iterative expansion</h2>
<div class="outline-text-2" id="text-12">

<div id="org5e38c04" class="figure">
<p><img src="./images/expansion.png" alt="expansion.png" />
</p>
</div>

<p>
In our method we provide an algorithm to iteratively expand the maximum \(r\) bound.
</p>

<div class="NOTES" id="orgab53b80">
<p>
Our method consists of iteratively expanding the maximum \(r\) bounds for each data
point simulateanously. If the bound intersects with a bound of data point from a
different class, then these two data points will stop expanding.
</p>

<p>
In this example we can see 3 data points, x<sub>1</sub>, x<sub>2</sub>, and x<sub>3</sub>. Where x<sub>1</sub>, and x<sub>3</sub>, are
from one class, and x<sub>2</sub> is from another. There are iterative steps for the expansion
of x<sub>1</sub> until it collides with the bound of x<sub>2</sub>. The bound of x<sub>3</sub> is ignored as its
from the same class.
</p>

</div>
</div>
</div>

<div id="outline-container-org269975f" class="outline-2">
<h2 id="org269975f"><span class="section-number-2">13</span> - Modulating by density</h2>
<div class="outline-text-2" id="text-13">
<p>
Expansion is modulated by the estimated density of data samples. Using an inverse multiquadric
radial basis function (RBF) to estimate the density at a given location.
</p>

<p>
\[
    \varphi(x; \overline{x}) =  \frac{1}{\sqrt{1 + (\varepsilon r)^2}},\; \text{where}\; r = \parallel \overline{x} - x \parallel
\]
</p>

<p>
The estimated density for a single point is the sum of RBFS, centered on each point,
at this location.
</p>

<p>
\[
    \rho_c(x) = \sum_{x_j \in X^c} \varphi(x; x_j)
\]
</p>

<div class="NOTES" id="orgdb1ad2c">
<p>
As we noted before, we may not have a lot of information in which to estimate the
class boundaries. This lack of information occurs due to the lack of sampling of
data. Therefore, we use this information of density of sampling to account for the
lack of information of class boundaries.
</p>

<p>
This density modulates the expansion of the $r$-bound. If there is not lots of
information about class boundaries, then the $r$-bound expansion will be a lot
smaller.
</p>

</div>
</div>
</div>

<div id="outline-container-org8fb5810" class="outline-2">
<h2 id="org8fb5810"><span class="section-number-2">14</span> - Final result: individual \(r\) value for each data point</h2>
<div class="outline-text-2" id="text-14">

<div id="org9acd83a" class="figure">
<p><img src="./images/iris-2.png" alt="iris-2.png" />
</p>
</div>

<p>
Morgan, J., Paiement, A., Pauly, A., &amp; Seisenberger, M. (2021). Adaptive
neighbourhoods for the discovery of adversarial examples. arXiv preprint
arXiv:2101.09108.
</p>

<div class="NOTES" id="orga7c4af3">
<p>
After computing the density of each data point and expanding the neighbourhoods, then
we will have an individual $r$-bound for each data point. This \(r\) provides the
upper-bound with which to search for adversarial examples.
</p>

<p>
We can seen this plot, that the black points have grown much larger due to the large
amounts of information about neighbours of the same class. While other points in the
top right have not grown much at all. In this plot we can still see overlaps, but
this is only because the neighbourhoods were computed at a higher number of
dimensions while this plot only shows 2 dimensions. At these higher dimensions the
neighbourhoods are not overlapping.
</p>

<p>
Here today, I have provided the iterative method to compute $r$-bounds, but we also
provide another method using langrangian multipliers to directly compute these
bounds. You can find the method in the paper "Adaptive neighbourhoods for the
discovery of adversarial examples".
</p>

</div>
</div>
</div>

<div id="outline-container-org7298cd9" class="outline-2">
<h2 id="org7298cd9"><span class="section-number-2">15</span> - Now we must find \(\textbf{x} + \epsilon\)</h2>
<div class="outline-text-2" id="text-15">

<div id="orgbcc029e" class="figure">
<p><img src="./images/perturbation.png" alt="perturbation.png" height="300px" />
</p>
</div>

<div class="NOTES" id="org7acaceb">
<p>
From the result of this iterative algorithm, we have an upper bound \(r\) value for
each data point. However, we have not yet found an adversarial example. To find such
an example, we must find some \(x + \epsilon\) where the model outputs a
miss-classification.
</p>

<p>
To find these examples, we can use our open-source platform.
</p>

</div>
</div>
</div>

<div id="outline-container-orgec6bcc0" class="outline-2">
<h2 id="orgec6bcc0"><span class="section-number-2">16</span> - Searching for the existence of adversarial examples</h2>
<div class="outline-text-2" id="text-16">

<div id="org93f1fc8" class="figure">
<p><img src="./images/neuralverifier.png" alt="neuralverifier.png" />
</p>
</div>

<p>
<a href="https://github.com/jaypmorgan/NeuralVerifier.jl">https://github.com/jaypmorgan/NeuralVerifier.jl</a> - built on top of Z3 solver to
provide an interface to verify Neural Network properties, such as: output bounds
checking and adversarial robustness.
</p>

<div class="NOTES" id="org526bdad">
<p>
Our open-source platform is called NeuralVerifier. It allows use to verify certain
properties of Neural Networks using Satisfiability Modulo Theories or SMT. We build
ontop of an existing and highly used SMT solver called Z3, which allows us to provide
more complex formulas to solve.
</p>

<p>
This next part of the talk will describe how we can create Neural Networks inside an
SMT solver, and then how NeuralVerifier abstracts away the work to make searching for
adversarial examples easier.
</p>

</div>
</div>
</div>

<div id="outline-container-org15c2c44" class="outline-2">
<h2 id="org15c2c44"><span class="section-number-2">17</span> - Application of using NeuralVerifier</h2>
<div class="outline-text-2" id="text-17">

<div id="orgaadd52d" class="figure">
<p><img src="./images/NN.png" alt="NN.png" height="400px" />
</p>
</div>

<p>
Take a very simple example of a 3-layer neural network.
</p>

<div class="NOTES" id="org00129be">
<p>
To motivate the explanation, take this very simple example of a 3 layer neural
network, with a single hidden layer in the middle.
</p>

<p>
This network takes in 3 inputs and produces three class outputs.
</p>

</div>
</div>
</div>

<div id="outline-container-org0bb62cc" class="outline-2">
<h2 id="org0bb62cc"><span class="section-number-2">18</span> - Simple Arithmetic</h2>
<div class="outline-text-2" id="text-18">
<p>
\[
z = \sigma(Wx + b)
\]
</p>


<div id="org9466c13" class="figure">
<p><img src="./images/neuron.png" alt="neuron.png" height="200px" />
</p>
</div>

<p>
Where \(\sigma\) is some non-linear function to increase the model's complexity to
allow it to model non-linear relationships. One of the most common non-linear
functions when training neural networks is the Rectified Linear activation function
(ReLU): \(\max(Wx+ b, 0)\).
</p>

<div class="NOTES" id="org406c959">
<p>
At a microlevel, the neural network performs a very simple equation, a Weight matrix
multiplied against the input vector, and the addition of the bias. A function is then
applied to the the result of this expression. This activation function in a
non-linearity which increases the learning capability of the network.
</p>

<p>
A very frequently used non-linear activation function is the ReLU activation function
which simply computes the maximum between the input and 0.
</p>

</div>
</div>
</div>

<div id="outline-container-orgc04c916" class="outline-2">
<h2 id="orgc04c916"><span class="section-number-2">19</span> - Encoding arithmetic</h2>
<div class="outline-text-2" id="text-19">
<p>
Z3 provides support for real linear arithmetic and provides operations for the basic
multiplication and addition. Thus, we need only to apply these elementwise.
</p>

<div class="org-src-container">
<pre class="src src-julia">function dense(x, W, b)
    out = fill!(Array(undef, size(W,1), size(x,2)), 0)

    for i = 1:size(out,1), j = 1:size(W,2)
	out[i] += W[i,j] * x[j]
    end

    out = out .+ b
    return out
end
</pre>
</div>

<div class="NOTES" id="org6ef4cfe">
<p>
As NeuralVerifier is built ontop of Z3, we can simply apply the arithmetic of this
neuron using constants in the network. So each layer of the neural network is just
the combination of the predefined weight matrix, the input and the bias.
</p>

</div>
</div>
</div>

<div id="outline-container-orge055c0a" class="outline-2">
<h2 id="orge055c0a"><span class="section-number-2">20</span> - ReLU</h2>
<div class="outline-text-2" id="text-20">
<p>
Moving onto non-linear functions, we must consider how such non-linearities are
encoded in the model. For some of the activation functions, it could be as easy as
simple boolean logic.
</p>

<p>
<code>If(x &gt; 0, x, 0)</code>
</p>


<div id="org2495df2" class="figure">
<p><img src="./images/relu.jpg" alt="relu.jpg" height="300px" />
</p>
</div>
</div>
</div>

<div id="outline-container-orged9a644" class="outline-2">
<h2 id="orged9a644"><span class="section-number-2">21</span> - More complex Sigmoid function (using piecewise linear approximation)</h2>
<div class="outline-text-2" id="text-21">
<div class="NOTES" id="org179e2a3">
<p>
However, encoding more complex activation functions can be reduced via piecewise
linear approximation with the same boolean arithmetic. Increasing the precision of
approximation will make satisfiability slower, but the encoding will be more true
with the original network.
</p>

</div>


<div id="org5a49cc6" class="figure">
<p><img src="./images/sigmoid.jpg" alt="sigmoid.jpg" height="300px" />
</p>
</div>

<div class="org-src-container">
<pre class="src src-julia">function sigmoid(x)
    If(x &lt; 0,
	If(x &lt; -2, 0.0, 0.4),
	If(x &gt;  2, 1.0, 0.6))
end
</pre>
</div>
</div>
</div>

<div id="outline-container-orge613224" class="outline-2">
<h2 id="orge613224"><span class="section-number-2">22</span> - Putting together a simple layer</h2>
<div class="outline-text-2" id="text-22">
<div class="org-src-container">
<pre class="src src-julia">function dense(x, W, b)
    out = fill!(Array(undef, size(W,1), size(x,2)), 0)

    for i = 1:size(out,1), j = 1:size(W,2)
	out[i] += W[i,j] * x[j]
    end

    out = out .+ b
    return out
end

function relu(x)
    If(x &gt; 0, x, 0)
end

y = relu(dense(x, W, b))
</pre>
</div>

<div class="NOTES" id="org271046b">
<p>
We can now compose these functions together in order to produce the result of a
single layer of the neural network.
</p>

</div>
</div>
</div>

<div id="outline-container-org2f0f859" class="outline-2">
<h2 id="org2f0f859"><span class="section-number-2">23</span> - Building an entire model with NeuralVerifier</h2>
<div class="outline-text-2" id="text-23">
<div class="org-src-container">
<pre class="src src-julia">encoding(x) = begin
    y = dense(x,
	      neural_network[1].W,
	      neural_network[1].b) |&gt; relu;
    y = dense(y,
	      neural_network[2].W,
	      neural_network[2].b) |&gt; relu;
    y = dense(y,
	      neural_network[3].W,
	      neural_network[3].b) |&gt; softmax;
end
</pre>
</div>

<div class="NOTES" id="org2780ee7">
<p>
In NeuralVerifier, this is all done for you. All you need to do is create a function
that takes some input \(x\), and apply the dense and non-linearity functions mimicing
the architectural design of your original network.
</p>

<p>
You can see we have passed the pretrained or prelearned weights and biases for each
layer of the network.
</p>

</div>
</div>
</div>

<div id="outline-container-org825f7ba" class="outline-2">
<h2 id="org825f7ba"><span class="section-number-2">24</span> - Setting up search for adversarial examples</h2>
<div class="outline-text-2" id="text-24">
<p>
\[
\min_{\epsilon} (\mathcal{F}(x) \neq \mathcal{F}(x + \epsilon)), \ \epsilon \leq r
\]
</p>

<div class="org-src-container">
<pre class="src src-julia">for (idx, (x_i, r_i)) in enumerate(zip(x, r))
    m = Optimize()  # create an optimisation procedure (model)

    add!(m, (eps &gt; 0) ∧ (eps &lt;= r_i)) # bound condition on epsilon

    y = encoding(x_i)  # get initial condition of y in our encoding

    add!(m, y != f(xi)) # add the adversarial example condition

    minimize!(m, eps)  # find the smallest eps

    check(m) # check for satisfiability

    m.is_sat == "sat" &amp;&amp; @info "#$(idx): Adversarial found!"
end
</pre>
</div>

<div class="NOTES" id="orgdf4541a">
<p>
To finalise we must add some conditions to specify we wish to search for adversarial
examples. In this case we setup an Optimisation model in Z3, we add the bounds
condition on epsilon being above 0, and less than or equal to r. We get the initial y
given our encoding function that we made earlier. Finally we add our adversarial
condition that the application of our classifier should not be equal to y.
</p>

<p>
We wish to finish epsilon here to find the closest possible adversarial example to
our original input.
</p>

<p>
Finally, we begin the search by using check, and print out if we have found an
adversarial example.
</p>

</div>
</div>
</div>

<div id="outline-container-org2b04908" class="outline-2">
<h2 id="org2b04908"><span class="section-number-2">25</span> - In NeuralVerifier</h2>
<div class="outline-text-2" id="text-25">
<div class="org-src-container">
<pre class="src src-julia">r = epsilon_expand(x_train', y_train;
    ϵ = 1e-7,                    # the initial step size
    ε = 1.0,                     # RBF width parameter
    func = inverse_multiquadric, # RBF function to use
    decay = exponential_decay)   # Decay function based on density

stable_area, adv_examples = stable_region(Optimize, f, x_train', r;
					  timeout = 100,
					  build_fn = encoding)
</pre>
</div>

<div class="NOTES" id="orgf3bd886">
<p>
In NeuralVerifier, we have abstracted all these details away and use higher order
functions. We have a function called epsilon<sub>expand</sub> which takes some density metric
and computes our upper-bounds for each data point in the data.
</p>

<p>
Then we use the stable region function, passing in our model, our data, and our
computed upper-bounds. The return of this function are the adversarial examples that
are found, and stable area. The stable area is a distance metric of how close to the
original inputs the model is robust against adversarial attacks. This kind of metric
might be useful for checking against specifications of using Neural Networks in
safety-critical systems.
</p>

</div>
</div>
</div>

<div id="outline-container-orge0bdcf2" class="outline-2">
<h2 id="orge0bdcf2"><span class="section-number-2">26</span> - Adversarial Examples Found!</h2>
<div class="outline-text-2" id="text-26">
<p>
Running on MNIST dataset.
</p>

<pre class="example" id="org6dd7196">
[ Info: #1: Adversarial found!
[ Info: #3: Adversarial found!
[ Info: #4: Adversarial found!
[ Info: #5: Adversarial found!
[ Info: #7: Adversarial found!
...
</pre>


<div id="orgbdc2f30" class="figure">
<p><img src="./images/example.png" alt="example.png" />
</p>
</div>

<div class="NOTES" id="orgece2951">
<p>
When we apply these functions to the MNIST dataset: a dataset of images of numbers,
where each image is classified by the number present in the image. You can see when
we run the stable<sub>area</sub> function it finds adversarial examples, and we can see just
one of these examples where a number 5 is recognised as a 3 by the Neural Network
when pixel modifications are applied.
</p>

</div>
</div>
</div>

<div id="outline-container-orga75150e" class="outline-2">
<h2 id="orga75150e"><span class="section-number-2">27</span> - Main contributions</h2>
<div class="outline-text-2" id="text-27">
<ol class="org-ol">
<li>Using knowledge gleamed from the data manifold to generate individual \(r\) value
for each data point.</li>
<li>Open-source platform for verification of Neural Network properties using SMT solvers</li>
</ol>

<div class="NOTES" id="org48fb71f">
<p>
To summarise this talk, I have presented two main contributions: the first, more
novel from a research perspective is the computation of upper-bounds for searching
for adversarial examples. This is not only useful for our NeuralVerifier framework,
but it also enables the use of existing adversarial generation techniques for
non-image data.
</p>

</div>
</div>
</div>

<div id="outline-container-org3569279" class="outline-2">
<h2 id="org3569279"><span class="section-number-2">28</span> - A thank you to my supervisors</h2>
<div class="outline-text-2" id="text-28">
<ul class="org-ul">
<li>Monika Seisenberger (Swansea University)</li>
<li>Jane Williams (Swansea University)</li>
<li>Adeline Paiement (Université de Toulon)</li>
</ul>

<div class="NOTES" id="org4d10c78">
<p>
Before I end my talk, its worth noting that this work is helped by supervisors and
funded by Swansea University.
</p>

</div>
</div>
</div>

<div id="outline-container-orgad2f914" class="outline-2">
<h2 id="orgad2f914"><span class="section-number-2">29</span> - Contributions welcome!</h2>
<div class="outline-text-2" id="text-29">
<p>
You can find these slides on my personal website below. Additionally follow the github link for
more documentation and usage on NeuralVerifier.jl
</p>

<ul class="org-ul">
<li><a href="https://blog.morganwastaken.com">https://blog.morganwastaken.com</a></li>
<li><a href="https://github.com/jaypmorgan/NeuralVerifier.jl">https://github.com/jaypmorgan/NeuralVerifier.jl</a></li>
</ul>

<div class="NOTES" id="org865b7e6">
<p>
The slides of this talk are available on my personal website linked here. And you can
also find the link to the NeuralVerifier platform where you can learn about, use, and
contribute to the development of the platform.
</p>

<p>
That's it for me, thank you for your time today.
</p>

</div>
</div>
</div>
</div>
<div id="postamble" class="status">
<p class="date">Date: 30th March 2021</p>
<p class="author">Author: Jay Morgan</p>
<p class="validation"><a href="https://validator.w3.org/check?uri=referer">Validate</a></p>
</div>
</body>
</html>
